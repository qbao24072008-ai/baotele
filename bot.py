import os
import asyncio
from openai import OpenAI
from telegram import (
    Update, ReplyKeyboardMarkup, InlineKeyboardMarkup, InlineKeyboardButton
)
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    ContextTypes, filters, CallbackQueryHandler
)
from pydub import AudioSegment

# Load config from env
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("Please set TELEGRAM_TOKEN and OPENAI_API_KEY in environment variables. See .env.example")

client = OpenAI(api_key=OPENAI_API_KEY)

# In-memory user memory (simple). For production use persistent storage.
user_memory = {}
last_user_image = {}  # store last downloaded image path per user

def add_message(user_id: int, role: str, content: str):
    if user_id not in user_memory:
        user_memory[user_id] = []
    user_memory[user_id].append({"role": role, "content": content})
    # Keep memory bounded
    if len(user_memory[user_id]) > 40:
        user_memory[user_id] = user_memory[user_id][-40:]

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_memory[user_id] = []
    menu = ReplyKeyboardMarkup(
        [["ğŸ§  Reset Memory", "ğŸ” Há»i láº¡i"], ["ğŸ“· Gá»­i áº¢nh", "ğŸ¤ Gá»­i Voice"], ["ğŸ“ Gá»­i File"]],
        resize_keyboard=True
    )
    await update.message.reply_text("Xin chÃ o! Bot AI Ä‘Ã£ sáºµn sÃ ng. Chá»n tÃ¡c vá»¥ tá»« menu hoáº·c gÃµ tin nháº¯n.", reply_markup=menu)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_memory[user_id] = []
    await update.message.reply_text("âœ… Memory Ä‘Ã£ Ä‘Æ°á»£c reset.")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text
    # If user pressed menu items (they are text), handle them
    if text in ["ğŸ§  Reset Memory", "ğŸ” Há»i láº¡i", "ğŸ“· Gá»­i áº¢nh", "ğŸ¤ Gá»­i Voice", "ğŸ“ Gá»­i File"]:
        return await menu_handler(update, context)

    add_message(user_id, "user", text)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    try:
        # Call OpenAI Chat Completion
        resp = client.chat.completions.create(
            model="gpt-4o-mini",  # change to an available model in your account
            messages=user_memory[user_id]
        )
        reply = resp.choices[0].message["content"]
    except Exception as e:
        reply = "âš ï¸ Lá»—i khi gá»i OpenAI: " + str(e)

    # Save assistant message to memory and send with inline buttons
    add_message(user_id, "assistant", reply)
    await send_ai_reply(update, reply)

async def send_ai_reply(update_or_ctx, text: str):
    # update_or_ctx can be Update or Context, but we expect Update in our calls
    update = update_or_ctx if isinstance(update_or_ctx, Update) else update_or_ctx._update
    inline = InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ”„ Há»i láº¡i", callback_data="retry"),
         InlineKeyboardButton("âŒ XoÃ¡ memory", callback_data="clear")]
    ])
    await update.message.reply_text(text, reply_markup=inline)

async def menu_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    if text == "ğŸ§  Reset Memory":
        await reset(update, context)
    elif text == "ğŸ” Há»i láº¡i":
        # Ask again last user message
        user_id = update.effective_user.id
        mem = user_memory.get(user_id, [])
        # find last user message
        last_user = None
        for m in reversed(mem):
            if m["role"] == "user":
                last_user = m["content"]
                break
        if last_user:
            # push it again, then call handler
            add_message(user_id, "user", last_user)
            await handle_text(update, context)
        else:
            await update.message.reply_text("KhÃ´ng cÃ³ lá»‹ch sá»­ Ä‘á»ƒ há»i láº¡i.")
    elif text == "ğŸ“· Gá»­i áº¢nh":
        await update.message.reply_text("HÃ£y gá»­i 1 áº£nh Ä‘á»ƒ bot lÆ°u/ xá»­ lÃ½.")
    elif text == "ğŸ¤ Gá»­i Voice":
        await update.message.reply_text("HÃ£y gá»­i voice message.")
    elif text == "ğŸ“ Gá»­i File":
        await update.message.reply_text("HÃ£y gá»­i file (txt / md / json Ä‘Æ°á»£c Æ°u tiÃªn).")


async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    photo = update.message.photo[-1]
    f = await photo.get_file()
    path = f"downloads/image_{user_id}_{photo.file_unique_id}.jpg"
    os.makedirs("downloads", exist_ok=True)
    await f.download_to_drive(path)
    last_user_image[user_id] = path
    await update.message.reply_text("ğŸ–¼ï¸ áº¢nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. GÃµ /analyze Ä‘á»ƒ phÃ¢n tÃ­ch cÆ¡ báº£n (hoáº·c mÃ´ táº£ báº¡n muá»‘n).")


async def analyze_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    path = last_user_image.get(user_id)
    if not path or not os.path.exists(path):
        await update.message.reply_text("KhÃ´ng tÃ¬m tháº¥y áº£nh Ä‘Ã£ gá»­i. Vui lÃ²ng gá»­i áº£nh trÆ°á»›c.")
        return
    await update.message.reply_text("Äang gá»­i áº£nh cho AI phÃ¢n tÃ­ch (lÆ°u Ã½: cáº§n model Vision/Responses há»— trá»£ áº£nh).") 
    try:
        # NOTE: this is a placeholder: actual image understanding requires OpenAI Responses or Vision API.
        # Here we will send a simple prompt telling the model there's an image at filename, and ask for general guidance.
        with open(path, "rb") as f:
            b = f.read()
        prompt = f"NgÆ°á»i dÃ¹ng gá»­i 1 áº£nh (Ä‘Ã£ lÆ°u tÃªn file). HÃ£y Ä‘Æ°a ra cÃ¡c gá»£i Ã½ phÃ¢n tÃ­ch náº¿u báº¡n khÃ´ng thá»ƒ xem áº£nh trá»±c tiáº¿p. "                  f"Náº¿u cÃ³ thá»ƒ phÃ¢n tÃ­ch áº£nh, mÃ´ táº£ cÃ¡c Ä‘á»‘i tÆ°á»£ng cÃ³ thá»ƒ xuáº¥t hiá»‡n vÃ  cÃ¢u há»i gá»£i Ã½ cho ngÆ°á»i dÃ¹ng."
        # We append system + user messages to memory and call chat model
        add_message(user_id, "user", "HÃ£y phÃ¢n tÃ­ch áº£nh tÃ´i vá»«a gá»­i.")
        add_message(user_id, "system", "áº¢nh Ä‘Æ°á»£c lÆ°u táº¡i server. (binary not sent).")
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=user_memory[user_id] + [{"role":"user","content":prompt}]
        )
        reply = resp.choices[0].message["content"]
    except Exception as e:
        reply = "Lá»—i khi phÃ¢n tÃ­ch áº£nh: " + str(e)
    add_message(user_id, "assistant", reply)
    await update.message.reply_text(reply)


async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    voice = update.message.voice or update.message.audio
    if not voice:
        await update.message.reply_text("KhÃ´ng tÃ¬m tháº¥y voice.")
        return
    f = await voice.get_file()
    ogg_path = f"downloads/voice_{user_id}_{voice.file_unique_id}.ogg"
    wav_path = ogg_path.replace(".ogg", ".wav")
    os.makedirs("downloads", exist_ok=True)
    await f.download_to_drive(ogg_path)
    try:
        # convert ogg -> wav using pydub (ffmpeg required)
        AudioSegment.from_file(ogg_path).export(wav_path, format="wav")
        await update.message.reply_text("Äang chuyá»ƒn giá»ng nÃ³i sang vÄƒn báº£n...")
        # send to OpenAI whisper transcription endpoint
        transcription = client.audio.transcriptions.create(
            model="gpt-4o-transcribe", # change if needed
            file=open(wav_path, "rb")
        )
        text = transcription.text
        add_message(user_id, "user", text)
        # get chat reply
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=user_memory[user_id]
        )
        reply = resp.choices[0].message["content"]
        add_message(user_id, "assistant", reply)
        await update.message.reply_text(f"ğŸ—£ï¸ Báº¡n nÃ³i: {text}\n\nğŸ¤– Bot tráº£ lá»i: {reply}")
    except Exception as e:
        await update.message.reply_text("Lá»—i khi xá»­ lÃ½ voice: " + str(e))


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    doc = update.message.document
    f = await doc.get_file()
    os.makedirs("downloads", exist_ok=True)
    path = f"downloads/{doc.file_name}"
    await f.download_to_drive(path)
    # Try to read text files (txt, md, json) and summarize
    try:
        if doc.file_name.lower().endswith(('.txt', '.md', '.json')):
            with open(path, "r", encoding="utf-8", errors="ignore") as fh:
                content = fh.read(100000)  # limit
            add_message(user_id, "user", f"ÄÃ£ gá»­i file: {doc.file_name}")
            # ask OpenAI to summarize
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role":"system","content":"Báº¡n lÃ  trá»£ lÃ½ tÃ³m táº¯t file."},
                          {"role":"user","content": "HÃ£y tÃ³m táº¯t ná»™i dung dÆ°á»›i Ä‘Ã¢y:\n\n" + content}]
            )
            reply = resp.choices[0].message["content"]
        else:
            reply = "File Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Hiá»‡n táº¡i bot chá»‰ tá»± tÃ³m táº¯t file text (txt, md, json)."
    except Exception as e:
        reply = "Lá»—i khi Ä‘á»c file: " + str(e)
    add_message(user_id, "assistant", reply)
    await update.message.reply_text(reply)


async def inline_button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    user_id = query.from_user.id
    if query.data == "retry":
        # Resend last user message content
        mem = user_memory.get(user_id, [])
        last_user = None
        for m in reversed(mem):
            if m["role"] == "user":
                last_user = m["content"]
                break
        if last_user:
            add_message(user_id, "user", last_user)
            # create a fake Update with last_user as message to reuse handle_text
            class FakeMsg: pass
            fake = FakeMsg()
            fake.message = query.message
            fake.message.text = last_user
            fake.message.from_user = query.from_user
            fake.message.chat = query.message.chat
            await handle_text(fake, context)
        else:
            await query.message.reply_text("KhÃ´ng cÃ³ tin nháº¯n trÆ°á»›c Ä‘á»ƒ há»i láº¡i.")
    elif query.data == "clear":
        user_memory[user_id] = []
        await query.message.reply_text("Memory Ä‘Ã£ Ä‘Æ°á»£c xoÃ¡.")


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("/start - Báº¯t Ä‘áº§u\n/reset - XoÃ¡ memory\n/analyze - PhÃ¢n tÃ­ch áº£nh vá»«a gá»­i\n/help - HÆ°á»›ng dáº«n\n\nGá»­i text/voice/image/file Ä‘á»ƒ bot xá»­ lÃ½.")


async def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(CommandHandler("analyze", analyze_image))
    app.add_handler(CommandHandler("help", help_cmd))

    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, handle_voice))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.Regex("ğŸ§ |ğŸ”|ğŸ“·|ğŸ¤|ğŸ“"), menu_handler))

    app.add_handler(CallbackQueryHandler(inline_button_handler))

    print("Bot AI Ä‘ang cháº¡y...")
    await app.run_polling()

if __name__ == '__main__':
    asyncio.run(main())
